[**ğŸ‡¨ğŸ‡³ä¸­æ–‡**](https://github.com/shibing624/MedicalGPT/blob/main/README.md) | [**ğŸŒEnglish**](https://github.com/shibing624/MedicalGPT/blob/main/README_EN.md) | [**ğŸ“–æ–‡æ¡£/Docs**](https://github.com/shibing624/MedicalGPT/wiki) | [**ğŸ¤–æ¨¡å‹/Models**](https://huggingface.co/shibing624)

-----------------

# MedicalGPT: Training Medical GPT Model
[![HF Models](https://img.shields.io/badge/Hugging%20Face-shibing624-green)](https://huggingface.co/shibing624)
[![Github Stars](https://img.shields.io/github/stars/shibing624/MedicalGPT?color=yellow)](https://star-history.com/#shibing624/MedicalGPT&Timeline)
[![Contributions welcome](https://img.shields.io/badge/contributions-welcome-brightgreen.svg)](CONTRIBUTING.md)
[![License Apache 2.0](https://img.shields.io/badge/license-Apache%202.0-blue.svg)](LICENSE)
[![python_version](https://img.shields.io/badge/Python-3.8%2B-green.svg)](requirements.txt)

## ğŸ“– Introduction

**MedicalGPT** training medical GPT model with ChatGPT training pipeline, implemantation of Pretraining,
Supervised Finetuning, RLHF(Reward Modeling and Reinforcement Learning) and DPO(Direct Preference Optimization).

**MedicalGPT** è®­ç»ƒåŒ»ç–—å¤§æ¨¡å‹ï¼Œå®ç°äº†åŒ…æ‹¬å¢é‡é¢„è®­ç»ƒã€æœ‰ç›‘ç£å¾®è°ƒã€RLHF(å¥–åŠ±å»ºæ¨¡ã€å¼ºåŒ–å­¦ä¹ è®­ç»ƒ)å’ŒDPO(ç›´æ¥åå¥½ä¼˜åŒ–)ã€‚

<img src="https://github.com/shibing624/MedicalGPT/blob/main/docs/dpo.jpg" width="860" />


## ğŸ˜Š Features


åŸºäºChatGPT Training Pipelineï¼Œæœ¬é¡¹ç›®å®ç°äº†é¢†åŸŸæ¨¡å‹--åŒ»ç–—è¡Œä¸šè¯­è¨€å¤§æ¨¡å‹çš„è®­ç»ƒï¼š


- ç¬¬ä¸€é˜¶æ®µï¼šPT(Continue PreTraining)å¢é‡é¢„è®­ç»ƒï¼Œåœ¨æµ·é‡é¢†åŸŸæ–‡æ¡£æ•°æ®ä¸ŠäºŒæ¬¡é¢„è®­ç»ƒGPTæ¨¡å‹ï¼Œä»¥é€‚åº”é¢†åŸŸæ•°æ®åˆ†å¸ƒï¼ˆå¯é€‰ï¼‰
- ç¬¬äºŒé˜¶æ®µï¼šSFT(Supervised Fine-tuning)æœ‰ç›‘ç£å¾®è°ƒï¼Œæ„é€ æŒ‡ä»¤å¾®è°ƒæ•°æ®é›†ï¼Œåœ¨é¢„è®­ç»ƒæ¨¡å‹åŸºç¡€ä¸ŠåšæŒ‡ä»¤ç²¾è°ƒï¼Œä»¥å¯¹é½æŒ‡ä»¤æ„å›¾ï¼Œå¹¶æ³¨å…¥é¢†åŸŸçŸ¥è¯†
- ç¬¬ä¸‰é˜¶æ®µ
  - RLHF(Reinforcement Learning from Human Feedback)åŸºäºäººç±»åé¦ˆå¯¹è¯­è¨€æ¨¡å‹è¿›è¡Œå¼ºåŒ–å­¦ä¹ ï¼Œåˆ†ä¸ºä¸¤æ­¥ï¼š
    - RM(Reward Model)å¥–åŠ±æ¨¡å‹å»ºæ¨¡ï¼Œæ„é€ äººç±»åå¥½æ’åºæ•°æ®é›†ï¼Œè®­ç»ƒå¥–åŠ±æ¨¡å‹ï¼Œç”¨æ¥å»ºæ¨¡äººç±»åå¥½ï¼Œä¸»è¦æ˜¯"HHH"åŸåˆ™ï¼Œå…·ä½“æ˜¯"helpful, honest, harmless"
    - RL(Reinforcement Learning)å¼ºåŒ–å­¦ä¹ ï¼Œç”¨å¥–åŠ±æ¨¡å‹æ¥è®­ç»ƒSFTæ¨¡å‹ï¼Œç”Ÿæˆæ¨¡å‹ä½¿ç”¨å¥–åŠ±æˆ–æƒ©ç½šæ¥æ›´æ–°å…¶ç­–ç•¥ï¼Œä»¥ä¾¿ç”Ÿæˆæ›´é«˜è´¨é‡ã€æ›´ç¬¦åˆäººç±»åå¥½çš„æ–‡æœ¬
  - [DPO(Direct Preference Optimization)](https://arxiv.org/pdf/2305.18290.pdf)ç›´æ¥åå¥½ä¼˜åŒ–æ–¹æ³•ï¼ŒDPOé€šè¿‡ç›´æ¥ä¼˜åŒ–è¯­è¨€æ¨¡å‹æ¥å®ç°å¯¹å…¶è¡Œä¸ºçš„ç²¾ç¡®æ§åˆ¶ï¼Œè€Œæ— éœ€ä½¿ç”¨å¤æ‚çš„å¼ºåŒ–å­¦ä¹ ï¼Œä¹Ÿå¯ä»¥æœ‰æ•ˆå­¦ä¹ åˆ°äººç±»åå¥½ï¼ŒDPOç›¸è¾ƒäºRLHFæ›´å®¹æ˜“å®ç°ä¸”æ˜“äºè®­ç»ƒï¼Œæ•ˆæœæ›´å¥½
  - [ORPO](https://arxiv.org/abs/2403.07691)æ¯”å€¼æ¯”åå¥½ä¼˜åŒ–ï¼Œä¸éœ€è¦å‚è€ƒæ¨¡å‹ï¼ˆref_modelï¼‰çš„ä¼˜åŒ–æ–¹æ³•ï¼Œé€šè¿‡ORPOï¼ŒLLMå¯ä»¥åŒæ—¶å­¦ä¹ SFTå’Œå¯¹é½ï¼Œå°†ä¸¤ä¸ªè¿‡ç¨‹æ•´åˆä¸ºå•ä¸€æ­¥éª¤ï¼Œç¼“è§£æ¨¡å‹ç¾éš¾æ€§é—å¿˜é—®é¢˜


### Release Models


| Model                                                                                                             | Base Model                                                                              | Introduction                                                                                                                                                                 |
|:------------------------------------------------------------------------------------------------------------------|:----------------------------------------------------------------------------------------|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| [shibing624/ziya-llama-13b-medical-lora](https://huggingface.co/shibing624/ziya-llama-13b-medical-lora)           | [IDEA-CCNL/Ziya-LLaMA-13B-v1](https://huggingface.co/IDEA-CCNL/Ziya-LLaMA-13B-v1)       | åœ¨240ä¸‡æ¡ä¸­è‹±æ–‡åŒ»ç–—æ•°æ®é›†[shibing624/medical](https://huggingface.co/datasets/shibing624/medical)ä¸ŠSFTå¾®è°ƒäº†ä¸€ç‰ˆZiya-LLaMA-13Bæ¨¡å‹ï¼ŒåŒ»ç–—é—®ç­”æ•ˆæœæœ‰æå‡ï¼Œå‘å¸ƒå¾®è°ƒåçš„LoRAæƒé‡(å•è½®å¯¹è¯)                                 |
| [shibing624/ziya-llama-13b-medical-merged](https://huggingface.co/shibing624/ziya-llama-13b-medical-merged)       | [IDEA-CCNL/Ziya-LLaMA-13B-v1](https://huggingface.co/IDEA-CCNL/Ziya-LLaMA-13B-v1)       | åœ¨240ä¸‡æ¡ä¸­è‹±æ–‡åŒ»ç–—æ•°æ®é›†[shibing624/medical](https://huggingface.co/datasets/shibing624/medical)ä¸ŠSFTå¾®è°ƒäº†ä¸€ç‰ˆZiya-LLaMA-13Bæ¨¡å‹ï¼ŒåŒ»ç–—é—®ç­”æ•ˆæœæœ‰æå‡ï¼Œå‘å¸ƒå¾®è°ƒåçš„å®Œæ•´æ¨¡å‹æƒé‡(å•è½®å¯¹è¯)                                 |
| [shibing624/vicuna-baichuan-13b-chat-lora](https://huggingface.co/shibing624/vicuna-baichuan-13b-chat-lora)       | [baichuan-inc/Baichuan-13B-Chat](https://huggingface.co/baichuan-inc/Baichuan-13B-Chat) | åœ¨10ä¸‡æ¡å¤šè¯­è¨€ShareGPT GPT4å¤šè½®å¯¹è¯æ•°æ®é›†[shibing624/sharegpt_gpt4](https://huggingface.co/datasets/shibing624/sharegpt_gpt4) å’Œ åŒ»ç–—æ•°æ®é›†[shibing624/medical](https://huggingface.co/datasets/shibing624/medical) ä¸ŠSFTå¾®è°ƒäº†ä¸€ç‰ˆbaichuan-13b-chatå¤šè½®é—®ç­”æ¨¡å‹ï¼Œæ—¥å¸¸é—®ç­”å’ŒåŒ»ç–—é—®ç­”æ•ˆæœæœ‰æå‡ï¼Œå‘å¸ƒå¾®è°ƒåçš„LoRAæƒé‡ |
| [shibing624/vicuna-baichuan-13b-chat](https://huggingface.co/shibing624/vicuna-baichuan-13b-chat)                 | [baichuan-inc/Baichuan-13B-Chat](https://huggingface.co/baichuan-inc/Baichuan-13B-Chat) | åœ¨10ä¸‡æ¡å¤šè¯­è¨€ShareGPT GPT4å¤šè½®å¯¹è¯æ•°æ®é›†[shibing624/sharegpt_gpt4](https://huggingface.co/datasets/shibing624/sharegpt_gpt4) å’Œ åŒ»ç–—æ•°æ®é›†[shibing624/medical](https://huggingface.co/datasets/shibing624/medical) ä¸ŠSFTå¾®è°ƒäº†ä¸€ç‰ˆbaichuan-13b-chatå¤šè½®é—®ç­”æ¨¡å‹ï¼Œæ—¥å¸¸é—®ç­”å’ŒåŒ»ç–—é—®ç­”æ•ˆæœæœ‰æå‡ï¼Œå‘å¸ƒå¾®è°ƒåçš„å®Œæ•´æ¨¡å‹æƒé‡ |
| [shibing624/llama-3-8b-instruct-262k-chinese](https://huggingface.co/shibing624/llama-3-8b-instruct-262k-chinese) | [Llama-3-8B-Instruct-262k](https://huggingface.co/gradientai/Llama-3-8B-Instruct-262k)  | åœ¨2ä¸‡æ¡ä¸­è‹±æ–‡åå¥½æ•°æ®é›†[shibing624/DPO-En-Zh-20k-Preference](https://huggingface.co/datasets/shibing624/DPO-En-Zh-20k-Preference)ä¸Šä½¿ç”¨ORPOæ–¹æ³•å¾®è°ƒå¾—åˆ°çš„è¶…é•¿æ–‡æœ¬å¤šè½®å¯¹è¯æ¨¡å‹ï¼Œé€‚ç”¨äºRAGã€å¤šè½®å¯¹è¯                   |

æ¼”ç¤º[shibing624/vicuna-baichuan-13b-chat](https://huggingface.co/shibing624/vicuna-baichuan-13b-chat)æ¨¡å‹æ•ˆæœï¼š
<img src="https://github.com/shibing624/MedicalGPT/blob/main/docs/demo-screen.gif" width="860" />
å…·ä½“caseè§[Inference Examples](#inference-examples)

## â–¶ï¸ Demo


æˆ‘ä»¬æä¾›äº†ä¸€ä¸ªç®€æ´çš„åŸºäºgradioçš„äº¤äº’å¼webç•Œé¢ï¼Œå¯åŠ¨æœåŠ¡åï¼Œå¯é€šè¿‡æµè§ˆå™¨è®¿é—®ï¼Œè¾“å…¥é—®é¢˜ï¼Œæ¨¡å‹ä¼šè¿”å›ç­”æ¡ˆã€‚

å¯åŠ¨æœåŠ¡ï¼Œå‘½ä»¤å¦‚ä¸‹ï¼š
```shell
CUDA_VISIBLE_DEVICES=0 python gradio_demo.py --base_model path_to_llama_hf_dir --lora_model path_to_lora_dir
```

å‚æ•°è¯´æ˜ï¼š

- `--base_model {base_model}`ï¼šå­˜æ”¾HFæ ¼å¼çš„LLaMAæ¨¡å‹æƒé‡å’Œé…ç½®æ–‡ä»¶çš„ç›®å½•ï¼Œä¹Ÿå¯ä½¿ç”¨HF Model Hubæ¨¡å‹è°ƒç”¨åç§°
- `--lora_model {lora_model}`ï¼šLoRAæ–‡ä»¶æ‰€åœ¨ç›®å½•ï¼Œä¹Ÿå¯ä½¿ç”¨HF Model Hubæ¨¡å‹è°ƒç”¨åç§°ã€‚è‹¥loraæƒé‡å·²ç»åˆå¹¶åˆ°é¢„è®­ç»ƒæ¨¡å‹ï¼Œåˆ™åˆ é™¤--lora_modelå‚æ•°
- `--tokenizer_path {tokenizer_path}`ï¼šå­˜æ”¾å¯¹åº”tokenizerçš„ç›®å½•ã€‚è‹¥ä¸æä¾›æ­¤å‚æ•°ï¼Œåˆ™å…¶é»˜è®¤å€¼ä¸--base_modelç›¸åŒ
- `--template_name`ï¼šæ¨¡æ¿åç§°ï¼Œå¦‚`vicuna`ã€`alpaca`ç­‰ã€‚è‹¥ä¸æä¾›æ­¤å‚æ•°ï¼Œåˆ™å…¶é»˜è®¤å€¼æ˜¯vicuna
- `--only_cpu`: ä»…ä½¿ç”¨CPUè¿›è¡Œæ¨ç†
- `--resize_emb`ï¼šæ˜¯å¦è°ƒæ•´embeddingå¤§å°ï¼Œè‹¥ä¸è°ƒæ•´ï¼Œåˆ™ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹çš„embeddingå¤§å°ï¼Œé»˜è®¤ä¸è°ƒæ•´


## ğŸ’¾ Install
#### Updating the requirements
`requirements.txt`ä¼šä¸æ—¶æ›´æ–°ä»¥é€‚é…æœ€æ–°åŠŸèƒ½ï¼Œä½¿ç”¨ä»¥ä¸‹å‘½ä»¤æ›´æ–°ä¾èµ–:

```markdown
git clone https://github.com/shibing624/MedicalGPT
cd MedicalGPT
pip install -r requirements.txt --upgrade
```

#### Hardware Requirement (æ˜¾å­˜/VRAM)


\* *ä¼°ç®—å€¼*

| è®­ç»ƒæ–¹æ³•  | ç²¾åº¦          |   7B  |  13B  |  30B  |   70B  |  110B  |  8x7B |  8x22B |
|-------|-------------| ----- | ----- | ----- | ------ | ------ | ----- | ------ |
| å…¨å‚æ•°   | AMP(è‡ªåŠ¨æ··åˆç²¾åº¦) | 120GB | 240GB | 600GB | 1200GB | 2000GB | 900GB | 2400GB |
| å…¨å‚æ•°   | 16          |  60GB | 120GB | 300GB |  600GB |  900GB | 400GB | 1200GB |
| LoRA  | 16          |  16GB |  32GB |  64GB |  160GB |  240GB | 120GB |  320GB |
| QLoRA | 8           |  10GB |  20GB |  40GB |   80GB |  140GB |  60GB |  160GB |
| QLoRA | 4           |   6GB |  12GB |  24GB |   48GB |   72GB |  30GB |   96GB |
| QLoRA | 2           |   4GB |   8GB |  16GB |   24GB |   48GB |  18GB |   48GB |

## ğŸš€ Training Pipeline

Training Stage:

| Stage                          | Introduction | Python script                                                                                           | Shell script                                                                  |
|:-------------------------------|:-------------|:--------------------------------------------------------------------------------------------------------|:------------------------------------------------------------------------------|
| Continue Pretraining           | å¢é‡é¢„è®­ç»ƒ        | [pretraining.py](https://github.com/shibing624/MedicalGPT/blob/main/pretraining.py)                     | [run_pt.sh](https://github.com/shibing624/MedicalGPT/blob/main/run_pt.sh)     |
| Supervised Fine-tuning         | æœ‰ç›‘ç£å¾®è°ƒ        | [supervised_finetuning.py](https://github.com/shibing624/MedicalGPT/blob/main/supervised_finetuning.py) | [run_sft.sh](https://github.com/shibing624/MedicalGPT/blob/main/run_sft.sh)   |
| Direct Preference Optimization | ç›´æ¥åå¥½ä¼˜åŒ–       | [dpo_training.py](https://github.com/shibing624/MedicalGPT/blob/main/dpo_training.py)                   | [run_dpo.sh](https://github.com/shibing624/MedicalGPT/blob/main/run_dpo.sh)   |
| Reward Modeling                | å¥–åŠ±æ¨¡å‹å»ºæ¨¡       | [reward_modeling.py](https://github.com/shibing624/MedicalGPT/blob/main/reward_modeling.py)             | [run_rm.sh](https://github.com/shibing624/MedicalGPT/blob/main/run_rm.sh)     |
| Reinforcement Learning         | å¼ºåŒ–å­¦ä¹          | [ppo_training.py](https://github.com/shibing624/MedicalGPT/blob/main/ppo_training.py)                   | [run_ppo.sh](https://github.com/shibing624/MedicalGPT/blob/main/run_ppo.sh)   |
| ORPO                           | æ¦‚ç‡åå¥½ä¼˜åŒ–       | [orpo_training.py](https://github.com/shibing624/MedicalGPT/blob/main/orpo_training.py)                  | [run_orpo.sh](https://github.com/shibing624/MedicalGPT/blob/main/run_orpo.sh) |

- æä¾›å®Œæ•´PT+SFT+DPOå…¨é˜¶æ®µä¸²èµ·æ¥è®­ç»ƒçš„pipelineï¼š[run_training_dpo_pipeline.ipynb](https://github.com/shibing624/MedicalGPT/blob/main/run_training_dpo_pipeline.ipynb) ï¼Œå…¶å¯¹åº”çš„colabï¼š [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/shibing624/MedicalGPT/blob/main/run_training_dpo_pipeline.ipynb)ï¼Œè¿è¡Œå®Œå¤§æ¦‚éœ€è¦15åˆ†é’Ÿ
- æä¾›å®Œæ•´PT+SFT+RLHFå…¨é˜¶æ®µä¸²èµ·æ¥è®­ç»ƒçš„pipelineï¼š[run_training_ppo_pipeline.ipynb](https://github.com/shibing624/MedicalGPT/blob/main/run_training_ppo_pipeline.ipynb) ï¼Œå…¶å¯¹åº”çš„colabï¼š [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/shibing624/MedicalGPT/blob/main/run_training_ppo_pipeline.ipynb) ï¼Œè¿è¡Œå®Œå¤§æ¦‚éœ€è¦20åˆ†é’Ÿ
- æä¾›åŸºäºçŸ¥è¯†åº“æ–‡ä»¶çš„LLMé—®ç­”åŠŸèƒ½ï¼ˆRAGï¼‰ï¼š[chatpdf.py](https://github.com/shibing624/MedicalGPT/blob/main/chatpdf.py)
- [è®­ç»ƒå‚æ•°è¯´æ˜](https://github.com/shibing624/MedicalGPT/blob/main/docs/training_params.md) | [è®­ç»ƒå‚æ•°è¯´æ˜wiki](https://github.com/shibing624/MedicalGPT/wiki/%E8%AE%AD%E7%BB%83%E5%8F%82%E6%95%B0%E8%AF%B4%E6%98%8E)
- [æ•°æ®é›†](https://github.com/shibing624/MedicalGPT/blob/main/docs/datasets.md) | [æ•°æ®é›†wiki](https://github.com/shibing624/MedicalGPT/wiki/%E6%95%B0%E6%8D%AE%E9%9B%86)
- [æ‰©å……è¯è¡¨](https://github.com/shibing624/MedicalGPT/blob/main/docs/extend_vocab.md) | [æ‰©å……è¯è¡¨wiki](https://github.com/shibing624/MedicalGPT/wiki/%E6%89%A9%E5%85%85%E4%B8%AD%E6%96%87%E8%AF%8D%E8%A1%A8)
- [FAQ](https://github.com/shibing624/MedicalGPT/blob/main/docs/FAQ.md) | [FAQ_wiki](https://github.com/shibing624/MedicalGPT/wiki/FAQ)

#### Supported Models

| Model Name                                                           | Model Size                    | Target Modules  | Template  |
|----------------------------------------------------------------------|-------------------------------|-----------------|-----------|
| [Baichuan](https://github.com/baichuan-inc/baichuan-13B)             | 7B/13B                        | W_pack          | baichuan  |
| [Baichuan2](https://github.com/baichuan-inc/Baichuan2)               | 7B/13B                        | W_pack          | baichuan2 |
| [BLOOMZ](https://huggingface.co/bigscience/bloomz)                   | 560M/1.1B/1.7B/3B/7.1B/176B   | query_key_value | vicuna    |
| [ChatGLM](https://github.com/THUDM/ChatGLM-6B)                       | 6B                            | query_key_value | chatglm   |
| [ChatGLM2](https://github.com/THUDM/ChatGLM2-6B)                     | 6B                            | query_key_value | chatglm2  |
| [ChatGLM3](https://github.com/THUDM/ChatGLM3)                        | 6B                            | query_key_value | chatglm3  |
| [Cohere](https://huggingface.co/CohereForAI/c4ai-command-r-plus)     | 104B                          | q_proj,v_proj   | cohere    |
| [DeepSeek](https://github.com/deepseek-ai/DeepSeek-LLM)              | 7B/16B/67B                    | q_proj,v_proj   | deepseek  |
| [DeepSeek3](https://github.com/deepseek-ai/DeepSeek-V3)              | 671B                         | q_proj,v_proj   | deepseek3 |
| [InternLM2](https://github.com/InternLM/InternLM)                    | 7B/20B                        | wqkv            | intern2   |
| [LLaMA](https://github.com/facebookresearch/llama)                   | 7B/13B/33B/65B                | q_proj,v_proj   | alpaca    |
| [LLaMA2](https://huggingface.co/meta-llama)                          | 7B/13B/70B                    | q_proj,v_proj   | llama2    |
| [LLaMA3](https://huggingface.co/meta-llama)                          | 8B/70B                        | q_proj,v_proj   | llama3    |
| [Mistral](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1) | 7B/8x7B                       | q_proj,v_proj   | mistral   |
| [Orion](https://github.com/OrionStarAI/Orion)                        | 14B                           | q_proj,v_proj   | orion     |
| [Qwen](https://github.com/QwenLM/Qwen)                               | 1.8B/7B/14B/72B               | c_attn          | qwen      |
| [Qwen1.5](https://huggingface.co/Qwen/Qwen1.5-72B)                   | 0.5B/1.8B/4B/14B/32B/72B/110B | q_proj,v_proj   | qwen      |
| [Qwen2](https://github.com/QwenLM/Qwen2)                             | 0.5B/1.5B/7B/72B              | q_proj,v_proj   | qwen      |
| [Qwen2.5](https://github.com/QwenLM/Qwen2.5)                         | 0.5B/1.8B/4B/14B/72B        | q_proj,v_proj   | qwen      |
| [XVERSE](https://github.com/xverse-ai/XVERSE-13B)                    | 13B                           | query_key_value | xverse    |
| [Yi](https://github.com/01-ai/Yi)                                    | 6B/34B                        | q_proj,v_proj   | yi        |




## ğŸ’» Inference
è®­ç»ƒå®Œæˆåï¼Œç°åœ¨æˆ‘ä»¬åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹ï¼ŒéªŒè¯æ¨¡å‹ç”Ÿæˆæ–‡æœ¬çš„æ•ˆæœã€‚

```shell
CUDA_VISIBLE_DEVICES=0 python inference.py \
    --base_model path_to_model_hf_dir \
    --lora_model path_to_lora \
    --interactive
```

å‚æ•°è¯´æ˜ï¼š

- `--base_model {base_model}`ï¼šå­˜æ”¾HFæ ¼å¼çš„LLaMAæ¨¡å‹æƒé‡å’Œé…ç½®æ–‡ä»¶çš„ç›®å½•
- `--tokenizer_path {base_model}`ï¼šå­˜æ”¾HFæ ¼å¼çš„LLaMAæ¨¡å‹æƒé‡å’Œé…ç½®æ–‡ä»¶çš„ç›®å½•
- `--lora_model {lora_model}`ï¼šLoRAè§£å‹åæ–‡ä»¶æ‰€åœ¨ç›®å½•ï¼Œä¹Ÿå¯ä½¿ç”¨HF Model Hubæ¨¡å‹è°ƒç”¨åç§°ã€‚å¦‚æœå·²ç»åˆå¹¶äº†LoRAæƒé‡åˆ°é¢„è®­ç»ƒæ¨¡å‹ï¼Œåˆ™å¯ä»¥ä¸æä¾›æ­¤å‚æ•°
- `--tokenizer_path {tokenizer_path}`ï¼šå­˜æ”¾å¯¹åº”tokenizerçš„ç›®å½•ã€‚è‹¥ä¸æä¾›æ­¤å‚æ•°ï¼Œåˆ™å…¶é»˜è®¤å€¼ä¸--base_modelç›¸åŒ
- `--template_name`ï¼šæ¨¡æ¿åç§°ï¼Œå¦‚`vicuna`ã€`alpaca`ç­‰ã€‚è‹¥ä¸æä¾›æ­¤å‚æ•°ï¼Œåˆ™å…¶é»˜è®¤å€¼æ˜¯vicuna
- `--interactive`ï¼šä»¥äº¤äº’æ–¹å¼å¯åŠ¨å¤šè½®é—®ç­”ï¼Œä½¿ç”¨æµå¼æ¨ç†
- `--data_file {file_name}`ï¼šéäº¤äº’æ–¹å¼å¯åŠ¨ä¸‹ï¼Œè¯»å–file_nameä¸­çš„çš„å†…å®¹è¿›è¡Œbatché¢„æµ‹
- `--output_file {file_name}`ï¼šéäº¤äº’å¼æ–¹å¼ä¸‹ï¼Œå°†é¢„æµ‹çš„ç»“æœä»¥jsonlæ ¼å¼å†™å…¥file_name
- `--resize_emb`ï¼šæ˜¯å¦è°ƒæ•´embeddingå¤§å°ï¼Œè‹¥ä¸è°ƒæ•´ï¼Œåˆ™ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹çš„embeddingå¤§å°ï¼Œé»˜è®¤ä¸è°ƒæ•´
- `--only_cpu`ï¼šä»…ä½¿ç”¨CPUè¿›è¡Œæ¨ç†
- `--gpus {gpu_ids}`ï¼šæŒ‡å®šä½¿ç”¨çš„GPUè®¾å¤‡ç¼–å·ï¼Œé»˜è®¤ä¸º0ã€‚å¦‚ä½¿ç”¨å¤šå¼ GPUï¼Œä»¥é€—å·åˆ†éš”ï¼Œå¦‚0,1,2



## ğŸ“š Dataset
### åŒ»ç–—æ•°æ®é›†

- 240ä¸‡æ¡ä¸­æ–‡åŒ»ç–—æ•°æ®é›†(åŒ…æ‹¬é¢„è®­ç»ƒã€æŒ‡ä»¤å¾®è°ƒå’Œå¥–åŠ±æ•°æ®é›†)ï¼š[shibing624/medical](https://huggingface.co/datasets/shibing624/medical)
- 22ä¸‡æ¡ä¸­æ–‡åŒ»ç–—å¯¹è¯æ•°æ®é›†(åä½—é¡¹ç›®)ï¼š[shibing624/huatuo_medical_qa_sharegpt](https://huggingface.co/datasets/shibing624/huatuo_medical_qa_sharegpt) ã€æœ¬é¡¹ç›®æ”¯æŒæ ¼å¼ã€‘



