***æœ¬é¡¹ç›®åŸºäºMedicalGPTé¡¹ç›®å‘å±•è€Œæ¥ï¼Œå°šå¤„äºç ”ç©¶é˜¶æ®µ***

----

# 


## â–¶ï¸ Demo


æˆ‘ä»¬æä¾›äº†ä¸€ä¸ªç®€æ´çš„åŸºäºgradioçš„äº¤äº’å¼webç•Œé¢ï¼Œå¯åŠ¨æœåŠ¡åï¼Œå¯é€šè¿‡æµè§ˆå™¨è®¿é—®ï¼Œè¾“å…¥é—®é¢˜ï¼Œæ¨¡å‹ä¼šè¿”å›ç­”æ¡ˆã€‚

å¯åŠ¨æœåŠ¡ï¼Œå‘½ä»¤å¦‚ä¸‹ï¼š
```shell
CUDA_VISIBLE_DEVICES=0 python gradio_demo.py --base_model path_to_llama_hf_dir --lora_model path_to_lora_dir
```

å‚æ•°è¯´æ˜ï¼š

- `--base_model {base_model}`ï¼šå­˜æ”¾HFæ ¼å¼çš„LLaMAæ¨¡å‹æƒé‡å’Œé…ç½®æ–‡ä»¶çš„ç›®å½•ï¼Œä¹Ÿå¯ä½¿ç”¨HF Model Hubæ¨¡å‹è°ƒç”¨åç§°
- `--lora_model {lora_model}`ï¼šLoRAæ–‡ä»¶æ‰€åœ¨ç›®å½•ï¼Œä¹Ÿå¯ä½¿ç”¨HF Model Hubæ¨¡å‹è°ƒç”¨åç§°ã€‚è‹¥loraæƒé‡å·²ç»åˆå¹¶åˆ°é¢„è®­ç»ƒæ¨¡å‹ï¼Œåˆ™åˆ é™¤--lora_modelå‚æ•°
- `--tokenizer_path {tokenizer_path}`ï¼šå­˜æ”¾å¯¹åº”tokenizerçš„ç›®å½•ã€‚è‹¥ä¸æä¾›æ­¤å‚æ•°ï¼Œåˆ™å…¶é»˜è®¤å€¼ä¸--base_modelç›¸åŒ
- `--template_name`ï¼šæ¨¡æ¿åç§°ï¼Œå¦‚`vicuna`ã€`alpaca`ç­‰ã€‚è‹¥ä¸æä¾›æ­¤å‚æ•°ï¼Œåˆ™å…¶é»˜è®¤å€¼æ˜¯vicuna
- `--only_cpu`: ä»…ä½¿ç”¨CPUè¿›è¡Œæ¨ç†
- `--resize_emb`ï¼šæ˜¯å¦è°ƒæ•´embeddingå¤§å°ï¼Œè‹¥ä¸è°ƒæ•´ï¼Œåˆ™ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹çš„embeddingå¤§å°ï¼Œé»˜è®¤ä¸è°ƒæ•´


## ğŸ’¾ Install
#### Updating the requirements
`requirements.txt`ä¼šä¸æ—¶æ›´æ–°ä»¥é€‚é…æœ€æ–°åŠŸèƒ½ï¼Œä½¿ç”¨ä»¥ä¸‹å‘½ä»¤æ›´æ–°ä¾èµ–:

```markdown
git clone https://github.com/shibing624/MedicalGPT
cd MedicalGPT
pip install -r requirements.txt --upgrade
```

#### Hardware Requirement (æ˜¾å­˜/VRAM)


\* *ä¼°ç®—å€¼*

| è®­ç»ƒæ–¹æ³• | ç²¾åº¦              | 7B    | 13B   | 30B   | 70B    | 110B   | 8x7B  | 8x22B  |
| -------- | ----------------- | ----- | ----- | ----- | ------ | ------ | ----- | ------ |
| å…¨å‚æ•°   | AMP(è‡ªåŠ¨æ··åˆç²¾åº¦) | 120GB | 240GB | 600GB | 1200GB | 2000GB | 900GB | 2400GB |
| å…¨å‚æ•°   | 16                | 60GB  | 120GB | 300GB | 600GB  | 900GB  | 400GB | 1200GB |
| LoRA     | 16                | 16GB  | 32GB  | 64GB  | 160GB  | 240GB  | 120GB | 320GB  |
| QLoRA    | 8                 | 10GB  | 20GB  | 40GB  | 80GB   | 140GB  | 60GB  | 160GB  |
| QLoRA    | 4                 | 6GB   | 12GB  | 24GB  | 48GB   | 72GB   | 30GB  | 96GB   |
| QLoRA    | 2                 | 4GB   | 8GB   | 16GB  | 24GB   | 48GB   | 18GB  | 48GB   |

## ğŸš€ Training Pipeline

Training Stage:

| Stage                          | Introduction | Python script                                                                                           | Shell script                                                                  |
| :----------------------------- | :----------- | :------------------------------------------------------------------------------------------------------ | :---------------------------------------------------------------------------- |
| Continue Pretraining           | å¢é‡é¢„è®­ç»ƒ   | [pretraining.py](https://github.com/shibing624/MedicalGPT/blob/main/pretraining.py)                     | [run_pt.sh](https://github.com/shibing624/MedicalGPT/blob/main/run_pt.sh)     |
| Supervised Fine-tuning         | æœ‰ç›‘ç£å¾®è°ƒ   | [supervised_finetuning.py](https://github.com/shibing624/MedicalGPT/blob/main/supervised_finetuning.py) | [run_sft.sh](https://github.com/shibing624/MedicalGPT/blob/main/run_sft.sh)   |
| Direct Preference Optimization | ç›´æ¥åå¥½ä¼˜åŒ– | [dpo_training.py](https://github.com/shibing624/MedicalGPT/blob/main/dpo_training.py)                   | [run_dpo.sh](https://github.com/shibing624/MedicalGPT/blob/main/run_dpo.sh)   |
| Reward Modeling                | å¥–åŠ±æ¨¡å‹å»ºæ¨¡ | [reward_modeling.py](https://github.com/shibing624/MedicalGPT/blob/main/reward_modeling.py)             | [run_rm.sh](https://github.com/shibing624/MedicalGPT/blob/main/run_rm.sh)     |
| Reinforcement Learning         | å¼ºåŒ–å­¦ä¹      | [ppo_training.py](https://github.com/shibing624/MedicalGPT/blob/main/ppo_training.py)                   | [run_ppo.sh](https://github.com/shibing624/MedicalGPT/blob/main/run_ppo.sh)   |
| ORPO                           | æ¦‚ç‡åå¥½ä¼˜åŒ– | [orpo_training.py](https://github.com/shibing624/MedicalGPT/blob/main/orpo_training.py)                 | [run_orpo.sh](https://github.com/shibing624/MedicalGPT/blob/main/run_orpo.sh) |

- æä¾›å®Œæ•´PT+SFT+DPOå…¨é˜¶æ®µä¸²èµ·æ¥è®­ç»ƒçš„pipelineï¼š[run_training_dpo_pipeline.ipynb](https://github.com/shibing624/MedicalGPT/blob/main/run_training_dpo_pipeline.ipynb) ï¼Œå…¶å¯¹åº”çš„colabï¼š [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/shibing624/MedicalGPT/blob/main/run_training_dpo_pipeline.ipynb)ï¼Œè¿è¡Œå®Œå¤§æ¦‚éœ€è¦15åˆ†é’Ÿ
- æä¾›å®Œæ•´PT+SFT+RLHFå…¨é˜¶æ®µä¸²èµ·æ¥è®­ç»ƒçš„pipelineï¼š[run_training_ppo_pipeline.ipynb](https://github.com/shibing624/MedicalGPT/blob/main/run_training_ppo_pipeline.ipynb) ï¼Œå…¶å¯¹åº”çš„colabï¼š [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/shibing624/MedicalGPT/blob/main/run_training_ppo_pipeline.ipynb) ï¼Œè¿è¡Œå®Œå¤§æ¦‚éœ€è¦20åˆ†é’Ÿ
- æä¾›åŸºäºçŸ¥è¯†åº“æ–‡ä»¶çš„LLMé—®ç­”åŠŸèƒ½ï¼ˆRAGï¼‰ï¼š[chatpdf.py](https://github.com/shibing624/MedicalGPT/blob/main/chatpdf.py)
- [è®­ç»ƒå‚æ•°è¯´æ˜](https://github.com/shibing624/MedicalGPT/blob/main/docs/training_params.md) | [è®­ç»ƒå‚æ•°è¯´æ˜wiki](https://github.com/shibing624/MedicalGPT/wiki/%E8%AE%AD%E7%BB%83%E5%8F%82%E6%95%B0%E8%AF%B4%E6%98%8E)
- [æ•°æ®é›†](https://github.com/shibing624/MedicalGPT/blob/main/docs/datasets.md) | [æ•°æ®é›†wiki](https://github.com/shibing624/MedicalGPT/wiki/%E6%95%B0%E6%8D%AE%E9%9B%86)
- [æ‰©å……è¯è¡¨](https://github.com/shibing624/MedicalGPT/blob/main/docs/extend_vocab.md) | [æ‰©å……è¯è¡¨wiki](https://github.com/shibing624/MedicalGPT/wiki/%E6%89%A9%E5%85%85%E4%B8%AD%E6%96%87%E8%AF%8D%E8%A1%A8)
- [FAQ](https://github.com/shibing624/MedicalGPT/blob/main/docs/FAQ.md) | [FAQ_wiki](https://github.com/shibing624/MedicalGPT/wiki/FAQ)

#### Supported Models

| Model Name                                                           | Model Size                    | Target Modules  | Template  |
| -------------------------------------------------------------------- | ----------------------------- | --------------- | --------- |
| [Baichuan](https://github.com/baichuan-inc/baichuan-13B)             | 7B/13B                        | W_pack          | baichuan  |
| [Baichuan2](https://github.com/baichuan-inc/Baichuan2)               | 7B/13B                        | W_pack          | baichuan2 |
| [BLOOMZ](https://huggingface.co/bigscience/bloomz)                   | 560M/1.1B/1.7B/3B/7.1B/176B   | query_key_value | vicuna    |
| [ChatGLM](https://github.com/THUDM/ChatGLM-6B)                       | 6B                            | query_key_value | chatglm   |
| [ChatGLM2](https://github.com/THUDM/ChatGLM2-6B)                     | 6B                            | query_key_value | chatglm2  |
| [ChatGLM3](https://github.com/THUDM/ChatGLM3)                        | 6B                            | query_key_value | chatglm3  |
| [Cohere](https://huggingface.co/CohereForAI/c4ai-command-r-plus)     | 104B                          | q_proj,v_proj   | cohere    |
| [DeepSeek](https://github.com/deepseek-ai/DeepSeek-LLM)              | 7B/16B/67B                    | q_proj,v_proj   | deepseek  |
| [DeepSeek3](https://github.com/deepseek-ai/DeepSeek-V3)              | 671B                          | q_proj,v_proj   | deepseek3 |
| [InternLM2](https://github.com/InternLM/InternLM)                    | 7B/20B                        | wqkv            | intern2   |
| [LLaMA](https://github.com/facebookresearch/llama)                   | 7B/13B/33B/65B                | q_proj,v_proj   | alpaca    |
| [LLaMA2](https://huggingface.co/meta-llama)                          | 7B/13B/70B                    | q_proj,v_proj   | llama2    |
| [LLaMA3](https://huggingface.co/meta-llama)                          | 8B/70B                        | q_proj,v_proj   | llama3    |
| [Mistral](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1) | 7B/8x7B                       | q_proj,v_proj   | mistral   |
| [Orion](https://github.com/OrionStarAI/Orion)                        | 14B                           | q_proj,v_proj   | orion     |
| [Qwen](https://github.com/QwenLM/Qwen)                               | 1.8B/7B/14B/72B               | c_attn          | qwen      |
| [Qwen1.5](https://huggingface.co/Qwen/Qwen1.5-72B)                   | 0.5B/1.8B/4B/14B/32B/72B/110B | q_proj,v_proj   | qwen      |
| [Qwen2](https://github.com/QwenLM/Qwen2)                             | 0.5B/1.5B/7B/72B              | q_proj,v_proj   | qwen      |
| [Qwen2.5](https://github.com/QwenLM/Qwen2.5)                         | 0.5B/1.8B/4B/14B/72B          | q_proj,v_proj   | qwen      |
| [XVERSE](https://github.com/xverse-ai/XVERSE-13B)                    | 13B                           | query_key_value | xverse    |
| [Yi](https://github.com/01-ai/Yi)                                    | 6B/34B                        | q_proj,v_proj   | yi        |




## ğŸ’» Inference
è®­ç»ƒå®Œæˆåï¼Œç°åœ¨æˆ‘ä»¬åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹ï¼ŒéªŒè¯æ¨¡å‹ç”Ÿæˆæ–‡æœ¬çš„æ•ˆæœã€‚

```shell
CUDA_VISIBLE_DEVICES=0 python inference.py \
    --base_model path_to_model_hf_dir \
    --lora_model path_to_lora \
    --interactive
```

å‚æ•°è¯´æ˜ï¼š

- `--base_model {base_model}`ï¼šå­˜æ”¾HFæ ¼å¼çš„LLaMAæ¨¡å‹æƒé‡å’Œé…ç½®æ–‡ä»¶çš„ç›®å½•
- `--tokenizer_path {base_model}`ï¼šå­˜æ”¾HFæ ¼å¼çš„LLaMAæ¨¡å‹æƒé‡å’Œé…ç½®æ–‡ä»¶çš„ç›®å½•
- `--lora_model {lora_model}`ï¼šLoRAè§£å‹åæ–‡ä»¶æ‰€åœ¨ç›®å½•ï¼Œä¹Ÿå¯ä½¿ç”¨HF Model Hubæ¨¡å‹è°ƒç”¨åç§°ã€‚å¦‚æœå·²ç»åˆå¹¶äº†LoRAæƒé‡åˆ°é¢„è®­ç»ƒæ¨¡å‹ï¼Œåˆ™å¯ä»¥ä¸æä¾›æ­¤å‚æ•°
- `--tokenizer_path {tokenizer_path}`ï¼šå­˜æ”¾å¯¹åº”tokenizerçš„ç›®å½•ã€‚è‹¥ä¸æä¾›æ­¤å‚æ•°ï¼Œåˆ™å…¶é»˜è®¤å€¼ä¸--base_modelç›¸åŒ
- `--template_name`ï¼šæ¨¡æ¿åç§°ï¼Œå¦‚`vicuna`ã€`alpaca`ç­‰ã€‚è‹¥ä¸æä¾›æ­¤å‚æ•°ï¼Œåˆ™å…¶é»˜è®¤å€¼æ˜¯vicuna
- `--interactive`ï¼šä»¥äº¤äº’æ–¹å¼å¯åŠ¨å¤šè½®é—®ç­”ï¼Œä½¿ç”¨æµå¼æ¨ç†
- `--data_file {file_name}`ï¼šéäº¤äº’æ–¹å¼å¯åŠ¨ä¸‹ï¼Œè¯»å–file_nameä¸­çš„çš„å†…å®¹è¿›è¡Œbatché¢„æµ‹
- `--output_file {file_name}`ï¼šéäº¤äº’å¼æ–¹å¼ä¸‹ï¼Œå°†é¢„æµ‹çš„ç»“æœä»¥jsonlæ ¼å¼å†™å…¥file_name
- `--resize_emb`ï¼šæ˜¯å¦è°ƒæ•´embeddingå¤§å°ï¼Œè‹¥ä¸è°ƒæ•´ï¼Œåˆ™ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹çš„embeddingå¤§å°ï¼Œé»˜è®¤ä¸è°ƒæ•´
- `--only_cpu`ï¼šä»…ä½¿ç”¨CPUè¿›è¡Œæ¨ç†
- `--gpus {gpu_ids}`ï¼šæŒ‡å®šä½¿ç”¨çš„GPUè®¾å¤‡ç¼–å·ï¼Œé»˜è®¤ä¸º0ã€‚å¦‚ä½¿ç”¨å¤šå¼ GPUï¼Œä»¥é€—å·åˆ†éš”ï¼Œå¦‚0,1,2



## ğŸ“š Dataset
### åŒ»ç–—æ•°æ®é›†

- 240ä¸‡æ¡ä¸­æ–‡åŒ»ç–—æ•°æ®é›†(åŒ…æ‹¬é¢„è®­ç»ƒã€æŒ‡ä»¤å¾®è°ƒå’Œå¥–åŠ±æ•°æ®é›†)ï¼š[shibing624/medical](https://huggingface.co/datasets/shibing624/medical)
- 22ä¸‡æ¡ä¸­æ–‡åŒ»ç–—å¯¹è¯æ•°æ®é›†(åä½—é¡¹ç›®)ï¼š[shibing624/huatuo_medical_qa_sharegpt](https://huggingface.co/datasets/shibing624/huatuo_medical_qa_sharegpt) ã€æœ¬é¡¹ç›®æ”¯æŒæ ¼å¼ã€‘



